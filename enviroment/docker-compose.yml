version: "3"
services:
  # ----------------------------  Zookeeper  ----------------------------
  zookeeper:
    image: zookeeper:3.4.9
    hostname: zookeeper
    container_name: zookeeper
    environment:
      ZOO_MY_ID: 1
      ZOO_PORT: 2181
      ZOO_SERVERS: server.1=zookeeper:2888:3888
    volumes:
      - zookeeper_data:/data
      - zookeeper_datalog:/datalog
    networks:
      - demo
    restart: always

  # ----------------------------  Kafka Broker 1  ----------------------------
  kafka:
    image: confluentinc/cp-kafka:5.3.0
    container_name: kafka-1
    ports:
      - "9092:9092"  # Puerto para conexiones externas
    environment:
      DOCKER_HOST_IP: $(hostname -I | awk '{print $1}')
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_NUM_NETWORK_THREADS: 8
      KAFKA_NUM_IO_THREADS: 16
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 10485760
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 10485760
      KAFKA_LOG_FLUSH_INTERVAL_MESSAGES: 10000
      KAFKA_LOG_FLUSH_INTERVAL_MS: 500
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_MESSAGE_MAX_BYTES: 10485760
      KAFKA_REPLICA_FETCH_MAX_BYTES: 52428800
    volumes:
      - kafka:/var/lib/kafka/data
    depends_on:
      - zookeeper
    networks:
      - demo
    restart: always

  # ----------------------------  Kafka Broker 2  ----------------------------
  kafka-2:
    image: confluentinc/cp-kafka:5.3.0
    container_name: kafka-2
    ports:
      - "9093:9093"  # Puerto externo diferente para evitar conflicto
    environment:
      DOCKER_HOST_IP: $(hostname -I | awk '{print $1}')
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka-2:19093,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 2
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1  # Ajustado para evitar problemas
      KAFKA_NUM_NETWORK_THREADS: 8
      KAFKA_NUM_IO_THREADS: 16
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 10485760
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 10485760
      KAFKA_LOG_FLUSH_INTERVAL_MESSAGES: 10000
      KAFKA_LOG_FLUSH_INTERVAL_MS: 500
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_MESSAGE_MAX_BYTES: 10485760
      KAFKA_REPLICA_FETCH_MAX_BYTES: 52428800
    volumes:
      - kafka-2:/var/lib/kafka/data
    depends_on:
      - zookeeper
    networks:
      - demo
    restart: always

  # ----------------------------  Kafdrop (Interfaz Gr√°fica)  ----------------------------
  kafdrop:
    image: obsidiandynamics/kafdrop
    container_name: kafdrop
    ports:
      - "4524:9000"
    environment:
      KAFKA_BROKERCONNECT: kafka:19092,kafka-2:19093  # Incluir ambos brokers
    depends_on:
      - kafka
      - kafka-2
    networks:
      - demo
    restart: always

# ----------------------------  Redes y Volumenes  ----------------------------
networks:
  demo:
    external: true

volumes:
  zookeeper_data:
  zookeeper_datalog:
  kafka:
  kafka-2: